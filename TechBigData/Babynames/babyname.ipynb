{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "# Propaganda, start the `spark` session\n",
    "\n",
    "> For SQL users, Spark SQL provides state-of-the-art SQL performance and maintains compatibility with Shark/Hive. In particular, like Shark, Spark SQL supports all existing Hive data formats, user-defined functions (UDF), and the Hive metastore.\n",
    "\n",
    "> For Spark users, Spark SQL becomes the narrow-waist for manipulating (semi-) structured data as well as ingesting data from sources that provide schema, such as JSON, Parquet, Hive, or EDWs. It truly unifies SQL and sophisticated analysis, allowing users to mix and match SQL and more imperative programming APIs for advanced analytics.\n",
    "\n",
    "> For open source hackers, Spark SQL proposes a novel, elegant way of building query planners. It is incredibly easy to add new optimizations under this framework.\n",
    "\n",
    "> Internally, a structured query is a Catalyst tree of (logical and physical) relational operators and expressions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:39.925342Z",
     "start_time": "2020-04-04T20:33:38.090254Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# import the usual suspects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "During the session, we will use classes and functions exported by `pyspark`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:40.082404Z",
     "start_time": "2020-04-04T20:33:39.928671Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# spark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.catalog import Catalog\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the `SparkSession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:46.600197Z",
     "start_time": "2020-04-04T20:33:40.087522Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Spark SQL Illustrations\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark SQL\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "US Baby Names 1880-2017\n",
    "=======================\n",
    "\n",
    "\n",
    "Description\n",
    ": US baby names provided by the SSA. \n",
    "\n",
    "This dataset contains all names used\n",
    "for at least 5 children of either sex during a year. \n",
    "\n",
    "\n",
    "The file is made of `1924665` lines and  4 columns.\n",
    "\n",
    "```\n",
    "|-- name: string (nullable = true)\n",
    "    |-- n: integer (nullable = true)\n",
    "    |-- sex: string (nullable = true)\n",
    "    |-- year: integer (nullable = true)\n",
    "```\n",
    "\n",
    "Each row indicates for a given name, sex, and year the number of babies \n",
    "of the given sex who were given that name during the given year. Names \n",
    "with less than 5 occurrences during the year were note recorded. \n",
    "\n",
    "|    name|  n|sex|year|\n",
    "|:--------|:---:|:---:|:----:|\n",
    "|  Emilia|112|  F|1985|\n",
    "|   Kelsi|112|  F|1985|\n",
    "|  Margot|112|  F|1985|\n",
    "|  Mariam|112|  F|1985|\n",
    "|Scarlett|112|  F|1985|\n",
    "\n",
    "First, we download the data if it's not there yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:46.839209Z",
     "start_time": "2020-04-04T20:33:46.603777Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('babynames_short.csv')\n",
    "if not path.exists():\n",
    "    url = \"https://stephanegaiffas.github.io/big_data_course/data/babynames_short.csv.zip\"\n",
    "    r = requests.get(url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(path='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "Load `babynames` from a `csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:58.538911Z",
     "start_time": "2020-04-04T20:33:46.841710Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_sp = spark.read\\\n",
    "             .format('csv')\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .option(\"mode\", \"FAILFAST\")\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .option(\"sep\", \",\")\\\n",
    "             .load(\"babynames_short.csv\")\n",
    "\n",
    "df_sp.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "Ensure that the dataframe has the following schema:\n",
    "\n",
    "    root\n",
    "        |-- name: string (nullable = true)\n",
    "        |-- n: integer (nullable = true)\n",
    "        |-- sex: string (nullable = true)\n",
    "        |-- year: integer (nullable = true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:59.042942Z",
     "start_time": "2020-04-04T20:33:58.542262Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "df_sp = df_sp.withColumn(\"year\", df_sp.year.cast(\"int\"))\n",
    "df_sp.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "SQL versus spark-Dataframe API\n",
    "=================================\n",
    "\n",
    ">  Dataset API vs SQL\n",
    "\n",
    "> Spark SQL supports two \"modes\" to write structured queries: Dataset API and SQL. SQL Mode is used to express structured queries using SQL statements using SparkSession.sql operator, expr standard function and spark-sql command-line tool.\n",
    "\n",
    "> Some structured queries can be expressed much easier using Dataset API, but there are some that are only possible in SQL. In other words, you may find mixing Dataset API and SQL modes challenging yet rewarding.\n",
    "\n",
    "> What is important, and one of the reasons why Spark SQL has been so successful, is that there is no performance difference between the modes. Whatever mode you use to write your structured queries, they all end up as a tree of Catalyst relational data structures. And, yes, you could consider writing structured queries using Catalyst directly, but that could quickly become unwieldy for maintenance (i.e. finding Spark SQL developers who could be comfortable with it as well as being fairly low-level and therefore possibly too dependent on a specific Spark SQL version).\n",
    "\n",
    "Warmup:  compute the 10 most popular names given to babies in year 2000.\n",
    "======================================================================\n",
    "\n",
    "## Using `spark.sql()`\n",
    "\n",
    "In order to use mode `sql`, create a temporary view from the `DataFrame`.\n",
    "\n",
    "1. What are temporary views made of?\n",
    "1. Are there other kind of views in spark's world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:33:59.616316Z",
     "start_time": "2020-04-04T20:33:59.047089Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "# 1. It's a lazily evaluated \"view\". In SQL, a view is a virtual table based on the result-set of an SQL statement.\n",
    "#    Temporary views in Spark SQL are session-scoped and will disappear if the session that creates it terminates.\n",
    "#    It does not persist in memory unless you cache the dataset that underpins the view. \n",
    "\n",
    "# 2. The only other \"type\" of view in the scala world is the Global Temporary view, but it's the same as the former\n",
    " #   but \"global\" to the application and not only the session\n",
    "Catalog(spark).listTables()\n",
    "# Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:00.166884Z",
     "start_time": "2020-04-04T20:33:59.631813Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_sp\n",
    "df.createOrReplaceTempView(\"babynames\")\n",
    "\n",
    "Catalog(spark).listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "## A query is a plain SQL query embodied in a string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:07.628624Z",
     "start_time": "2020-04-04T20:34:00.177966Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM babynames\n",
    "WHERE (year = {0} AND sex = {1})\n",
    "ORDER BY n DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query.format(2000, \"'M'\")).union(spark.sql(query.format(2000, \"'F'\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "> This phrasing is not consistent with the DRY principle. Fix this using formatted strings.\n",
    "\n",
    "## Using the dataframe/dataset API\n",
    "\n",
    "This can also be done using Spark SQL API.\n",
    "\n",
    "### Pedestrian approach\n",
    "\n",
    "1. First select `10` most popular names for girls in year `2000`, define `spark` dataframe\n",
    "`top10_2000_f`.\n",
    "1. Does the definition of `top10_2000_f` involve _transformations_, _actions_ or both?\n",
    "1. What is the type of the result returned by `top10_2000_f.take(2)`? the type of elements of the result?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:14.902449Z",
     "start_time": "2020-04-04T20:34:07.636017Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "top10_2000_f = df.where(\"sex = 'F'\").where(\"year = 2000\").orderBy(df.n.desc()).limit(10)\n",
    "top10_2000_f.show()\n",
    "type(top10_2000_f.take(2)) # It's a 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:17.587973Z",
     "start_time": "2020-04-04T20:34:14.906358Z"
    }
   },
   "outputs": [],
   "source": [
    "type(top10_2000_f.take(2)[0]) #pyspark.sql.types.Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "1. Do the same thing for boys.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:20.266157Z",
     "start_time": "2020-04-04T20:34:17.591286Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "top10_2000_m = df.where(\"sex = 'M'\").where(\"year = 2000\").orderBy(df.n.desc()).limit(10)\n",
    "top10_2000_m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "1. Compute the _union_ of the two spark dataframes. Store the result in\n",
    "dataframe `top10_2000`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:25.451727Z",
     "start_time": "2020-04-04T20:34:20.269534Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "top10_2000 = top10_2000_f.union(top10_2000_m)\n",
    "top10_2000.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "### Do it again, complying  with DRY principle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:30.804946Z",
     "start_time": "2020-04-04T20:34:25.455005Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = df.where(\"0 = 1\")\n",
    "genders = [\"'M'\", \"'F'\"]\n",
    "for g in genders: \n",
    "    temp_df = temp_df.union(df.where(\"year = 2000\").where(\"\".join([\"sex = \", g])).orderBy(df.n.desc()).limit(10))\n",
    "temp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "Name portfolio through ages\n",
    "===========================\n",
    "\n",
    "1. Compute for each year and sex the number of distinct names given that year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:39.263346Z",
     "start_time": "2020-04-04T20:34:30.809288Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "nb_names_year_sex = df.orderBy(df.year.asc()).groupBy('year', 'sex').count()\n",
    "window = Window.partitionBy('year')\n",
    "count = fn.sum('count').over(window)\n",
    "nb_names_year_sex = nb_names_year_sex.withColumn('total_count', count)\n",
    "nb_names_year_sex.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "1. Plot the evolution of the number of distinct names as a function of `year`.\n",
    "Use some aesthetics to distinguish sexes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:49.145113Z",
     "start_time": "2020-04-04T20:34:39.267504Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "pd_df = nb_names_year_sex.toPandas()\n",
    "pd_df\n",
    "p = sns.lineplot(data=pd_df, x='year', y='count', hue='sex')\n",
    "p.set_title(\"Number of distinct names with more than 5 occurrences\")\n",
    "\n",
    "plt.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "Assessing popularity through time\n",
    "=================================\n",
    "\n",
    "1. For each year and sex, compute the total number of births\n",
    "1. Plot the evolution of the sex ratio over time\n",
    "1. For each year, sex, and name compute the percentage of newborns\n",
    "given that name for that given year.\n",
    "\n",
    "\n",
    "> Use `Window` functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:34:59.676071Z",
     "start_time": "2020-04-04T20:34:49.148078Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "births = df.withColumn('births', fn.sum('n').over(Window.partitionBy('year', 'sex').orderBy('year'))) \\\n",
    "    .groupBy('year', 'sex', 'births').count() \\\n",
    "    .select('year', 'sex', 'births') \\\n",
    "    .withColumn('total', fn.sum('births').over(Window.partitionBy('year').orderBy('year')))\n",
    "births.orderBy('year', 'sex').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:35:25.131689Z",
     "start_time": "2020-04-04T20:34:59.683749Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "df_sex_ratio = births.groupBy(\"year\") \\\n",
    "    .pivot(\"sex\") \\\n",
    "    .sum(\"births\") \\\n",
    "    .withColumn(\"sex_ratio\", fn.round(col(\"M\")/col(\"F\"), 2)) \\\n",
    "    .orderBy(\"year\").select(\"year\", \"M\", \"F\", \"sex_ratio\")\n",
    "df_sex_ratio.show(5)\n",
    "\n",
    "q = sns.lineplot(data=df_sex_ratio.toPandas(), x='year', y='sex_ratio')\n",
    "q.set_title(\"Evolution of the sex ratio over time\")\n",
    "plt.show(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "1. Compute for each year, sex and name  the `row_number`, `rank`, and `dense_rank`\n",
    "of the name within that year and sex category, when names are sorted by increasing popularity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:35:32.679183Z",
     "start_time": "2020-04-04T20:35:25.135525Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "window = Window.partitionBy('year', 'sex').orderBy(df.n.desc())\n",
    "rank = fn.rank().over(window)\n",
    "dense_rank = fn.dense_rank().over(window)\n",
    "row_number = fn.row_number().over(window)\n",
    "\n",
    "rank_df = df.withColumn('row_number', row_number) \\\n",
    "    .withColumn('rank', rank) \\\n",
    "    .withColumn('dense_rank', dense_rank)\n",
    "rank_df.orderBy('year', rank_df.n.desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Evolution of top popular names through the century\n",
    "==================================================\n",
    "\n",
    "\n",
    "1. For each sex, select the ten most popular names in year 2000, and plot the proportion\n",
    "of newborns given that name over time. Take into account that some names might have\n",
    "zero occurrence during certain years.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:35:55.014551Z",
     "start_time": "2020-04-04T20:35:32.682881Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "popular_df = rank_df.where('year = 2000') \\\n",
    "    .where(\"dense_rank <= 10\")\n",
    "popular_df.show()\n",
    "popular_over_time = popular_df.select('name', 'sex') \\\n",
    "    .join(df, ['name', 'sex'], \"left\") \\\n",
    "    .join(births.where('sex = \"M\"').select('year', 'total'), 'year', 'left')\n",
    "popular_over_time = popular_over_time.withColumn('proportion', popular_over_time['n'] / popular_over_time['total'])\n",
    "popular_over_time.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "1. Use `explain()` to determine the joining strategy used by spark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:35:55.348644Z",
     "start_time": "2020-04-04T20:35:55.031180Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_over_time.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot  the popularity of each of the top ten achievers from year 2000 with respect to time\n",
    "=================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:36:16.056276Z",
     "start_time": "2020-04-04T20:35:55.356010Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_pot = popular_over_time.toPandas()\n",
    "sns.set(rc={'figure.figsize':(12,8)}, style='whitegrid')\n",
    "q = sns.lineplot(data=pd_pot, x='year', y='proportion', hue='name', style='sex')\n",
    "q.set_title(\"Popularity of each of the top ten names from year 2000 with respect to time \")\n",
    "plt.show(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "Plot the total popularity of the top ten achievers from year 2000 with respect to time\n",
    "==================================================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:36:39.818753Z",
     "start_time": "2020-04-04T20:36:16.069964Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pot = popular_over_time.withColumn('total_proportion', fn.sum('proportion').over(Window.partitionBy('year')))\n",
    "pot = pot.select('year', 'total_proportion')\n",
    "sns.set(rc={'figure.figsize':(12,6)}, style='whitegrid')\n",
    "q = sns.lineplot(data=pot.toPandas(), x='year', y='total_proportion')\n",
    "q.set_title(\"Total popularity of the top ten names from year 2000 as a function of time\")\n",
    "plt.show(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    " \n",
    "Plot lorenz curves\n",
    "=====================\n",
    "\n",
    "Every year, the name counts define a discrete probability distribution.\n",
    "This distribution, just as income or wealth distribution,\n",
    "is (usually) far from being uniform. We want to assess how uneven it is.\n",
    "We use the tools developed in econometrics.\n",
    "\n",
    "Without loss of generality, that we handle a distribution over $1, \\ldots, n$\n",
    "where $n$ is the number of distinct names given during a year.\n",
    "We assume that frequencies $p_1, p_2, \\ldots, p_n$ are given in ascending order.\n",
    "\n",
    "The Lorenz function maps $[0, 1] \\to [0, 1]$.\n",
    "$$L(x) = \\sum_{i=1}^{\\lfloor nx \\rfloor} p_i$$.\n",
    "\n",
    "1. Design a query that adds a column \"lorenz\" to the dataframe , and for each\n",
    "row computes the value of the Lorenz function defined by `year`  and `sex`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:37:00.678349Z",
     "start_time": "2020-04-04T20:36:39.822257Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "lor = df.withColumn('births', fn.sum('n').over(Window.partitionBy('year', 'sex').orderBy('year'))) \\\n",
    "    .groupBy('year', 'sex', 'births').count() \\\n",
    "    .select('year', 'sex', 'births') \\\n",
    "    .join(df, ['year', 'sex'], \"right\") \\\n",
    "    .withColumn('annual_proportion', col('n')/col('births')) \\\n",
    "    .withColumn('lorenz', fn.sum('annual_proportion') \\\n",
    "                .over(Window.partitionBy('year', 'sex')\\\n",
    "                .orderBy('annual_proportion') \\\n",
    "                .rangeBetween(Window.unboundedPreceding, 0))) \\\n",
    "    .withColumn('row', fn.row_number().over(Window.partitionBy('year', 'sex')\\\n",
    "                .orderBy('annual_proportion'))) \\\n",
    "    .withColumn('normalized_row', col('row') / fn.max('row').over(Window.partitionBy('year', 'sex')))\n",
    "lor.orderBy(lor.year.desc(), lor.sex.asc(), lor.lorenz.desc()).show()\n",
    "lor = lor.drop('births', 'n', 'births')\n",
    "lor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:37:14.959223Z",
     "start_time": "2020-04-04T20:37:00.682354Z"
    }
   },
   "outputs": [],
   "source": [
    "pd_lor = lor.where(\"year = 2017\").toPandas()\n",
    "sns.lineplot(data=pd_lor, x='normalized_row', y='lorenz', hue='sex')\n",
    "q = sns.lineplot(x=[0,1], y=[0,1], color='green', dashes=True, label='x = y')\n",
    "q.set_title(\"Normalized Lorenz function\")\n",
    "plt.show(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "1. Design a function that takes as input a `year` and plots the Lorenz curve\n",
    "for that year for both sexes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:42:59.404801Z",
     "start_time": "2020-04-04T20:42:59.388685Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "query = lambda y: df.where('year = {}'.format(y)) \\\n",
    "    .withColumn('births', fn.sum('n').over(Window.partitionBy('sex'))) \\\n",
    "    .groupBy('year', 'sex', 'births').count() \\\n",
    "    .select('year', 'sex', 'births') \\\n",
    "    .join(df, ['year', 'sex'], \"left\") \\\n",
    "    .withColumn('annual_proportion', col('n')/col('births')) \\\n",
    "    .withColumn('lorenz', fn.sum('annual_proportion') \\\n",
    "                .over(Window.partitionBy('sex')\\\n",
    "                .orderBy('annual_proportion') \\\n",
    "                .rangeBetween(Window.unboundedPreceding, 0))) \\\n",
    "    .withColumn('row', fn.row_number().over(Window.partitionBy('sex')\\\n",
    "                .orderBy('annual_proportion'))) \\\n",
    "    .withColumn('normalized_row', col('row') / fn.max('row').over(Window.partitionBy('sex')))\n",
    "\n",
    "def lorenz_plot(year):\n",
    "    lorenz_df = query(year)\n",
    "    sns.lineplot(data=lorenz_df.toPandas(), x='normalized_row', y='lorenz', hue='sex')\n",
    "    q = sns.lineplot(x=[0,1], y=[0,1], color='green', dashes=True, label='x = y')\n",
    "    q.set_title(\"Lorenz function during the year \"+str(year))\n",
    "    plt.show(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:43:12.502995Z",
     "start_time": "2020-04-04T20:43:02.597335Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lorenz_plot(1890)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "Gini index\n",
    "==========\n",
    "\n",
    "The [Gini index](https://en.wikipedia.org/wiki/Gini_coefficient) is twice the surface of the area comprised between curves $y=x$\n",
    "and $y=L(x)$.\n",
    "\n",
    "Choose a formula that allows you to compute it efficiently.\n",
    "\n",
    "$$G={\\frac {2\\sum _{i=1}^{n}iy_{i}}{n\\sum _{i=1}^{n}y_{i}}}-{\\frac {n+1}{n}}.$$\n",
    "\n",
    "1. Design a query that computes the Gini index of the `babynames` distribution\n",
    "for every `year` and `sex`.\n",
    "\n",
    "1. Plot Gini index over time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:37:54.148305Z",
     "start_time": "2020-04-04T20:37:50.438894Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "iy_i =  col(\"row\")*col(\"annual_proportion\")\n",
    "index_max = fn.max(\"row\").over(Window.partitionBy(\"year\", \"sex\"))\n",
    "den = index_max*fn.sum(\"annual_proportion\").over(Window.partitionBy(\"year\", \"sex\"))\n",
    "nb_births = fn.sum('n').over(Window.partitionBy('year', 'sex').orderBy('year'))\n",
    "\n",
    "gini_df = df.withColumn(\"row\", fn.row_number().over(Window.partitionBy(\"year\", \"sex\").orderBy(\"n\"))) \\\n",
    "    .withColumn('annual_proportion', col('n')/nb_births) \\\n",
    "    .withColumn(\"gini\", (2*fn.sum(iy_i).over(Window.partitionBy(\"year\", \"sex\"))/den ) - (index_max+1)/index_max)\n",
    "\n",
    "gini_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:39:34.196529Z",
     "start_time": "2020-04-04T20:38:05.026470Z"
    },
    "autoscroll": "auto",
    "options": {
     "caption": false,
     "complete": true,
     "display_data": true,
     "display_stream": true,
     "dpi": 200,
     "echo": true,
     "evaluate": false,
     "f_env": null,
     "f_pos": "htpb",
     "f_size": [
      6,
      4
     ],
     "f_spines": true,
     "fig": true,
     "include": true,
     "name": null,
     "option_string": "evaluate=False",
     "results": "verbatim",
     "term": false,
     "wrap": "output"
    }
   },
   "outputs": [],
   "source": [
    "gini = gini_df.toPandas()\n",
    "q = sns.lineplot(x=\"year\", y=\"gini\", data=gini, hue=\"sex\")\n",
    "q.set_title(\"Gini index over time\")\n",
    "plt.show(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "text/markdown"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Close the door, leave work area clean\n",
    "=====================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T20:45:05.268669Z",
     "start_time": "2020-04-04T20:45:04.682116Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
